{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5feaada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6345e1",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3590571",
   "metadata": {},
   "source": [
    "Read the dataset in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7248c704",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c1c685",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a6a064",
   "metadata": {},
   "source": [
    "First of all, search for missing values in the dataset. if there are missing values, handle them however you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ad824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d75210",
   "metadata": {},
   "source": [
    "Then, read the dataset catalog. There are some categorical features with the \"int\" type. Encode these features so that you can distinguish between numerical and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25de8d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age         category\n",
      "sex         category\n",
      "cp          category\n",
      "trestbps    category\n",
      "chol        category\n",
      "fbs         category\n",
      "restecg     category\n",
      "thalach     category\n",
      "exang       category\n",
      "oldpeak     category\n",
      "slope       category\n",
      "ca          category\n",
      "thal        category\n",
      "target         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data['sex'] = pd.cut(data['sex'], bins=[-np.inf, 0, np.inf], labels=['female', 'male'])\n",
    "data['cp'] = pd.cut(data['cp'], bins=[-np.inf, 0, 1, 2, np.inf], labels=['Value 1', 'Value 2', 'Value 3', 'Value 4'])\n",
    "data['fbs'] = pd.cut(data['fbs'], bins=[-np.inf, 0, np.inf], labels=['false', 'true'])\n",
    "data['restecg'] = pd.cut(data['restecg'], bins=[-np.inf, 0, 1, np.inf], labels=['Value 0', 'Value 1', 'Value 2'])\n",
    "data['exang'] = pd.cut(data['exang'], bins=[-np.inf, 0, np.inf], labels=['no', 'yes'])\n",
    "data['slope'] = pd.cut(data['slope'], bins=[-np.inf, 0, 1, np.inf], labels=['Value 1', 'Value 2', 'Value 3'])\n",
    "data['ca'] = pd.cut(data['ca'], bins=[-np.inf, 0, 1, 2, np.inf], labels=['0 major vessels', '1 major vessels', '2 major vessels', '3 major vessels'])\n",
    "data['thal'] = pd.cut(data['thal'], bins=[-np.inf, 1, 2, np.inf], labels=['normal', 'fixed defect', 'reversable defect'])\n",
    "\n",
    "data['age'] = pd.cut(data['age'], bins=[-np.inf, 35, 45, 55, 65, np.inf], labels=['<35', '35-45', '45-55', '55-65', '65<'])\n",
    "data['trestbps'] = pd.cut(data['trestbps'], bins=[-np.inf, 100, 110, 120, 130, 140, 150, np.inf], labels=['<100', '100-110', '110-120', '120-130', '130-140', '140-150', '150<'])\n",
    "data['chol'] = pd.cut(data['chol'], bins=[-np.inf, 150, 200, 250, 300, 350, 400, np.inf], labels=['<150', '150-200', '200-250', '250-300', '300-350', '350-400', '400<'])\n",
    "data['thalach'] = pd.cut(data['thalach'], bins=[-np.inf, 140, 150, 160, 170, 180, 190, np.inf], labels=['<140', '140-150', '150-160', '160-170', '170-180', '180-190', '190<'])\n",
    "data['oldpeak'] = pd.cut(data['oldpeak'], bins=[-np.inf, 0.5, 1, 1.5, 2, 2.5, np.inf], labels=['<0.5', '0.5-1', '1-1.5', '1.5-2', '2-2.5', '2.5<'])\n",
    "\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac80b358",
   "metadata": {},
   "source": [
    "### Declare feature vector and target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd380b7b",
   "metadata": {},
   "source": [
    "Here, you are supposed to convert pandas data frame into feature vectors and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf356570",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc35fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.T[0:13].T\n",
    "Y = data.T[13].T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526a17a0",
   "metadata": {},
   "source": [
    "### Split data into separate training and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25fd9b6",
   "metadata": {},
   "source": [
    "Now it's time to split X and y into separate training and test set. You can use the sklearn library for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dacf4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)\n",
    "X_train = X_train.tolist()\n",
    "X_test = X_test.tolist()\n",
    "Y_train = Y_train.tolist()\n",
    "Y_test = Y_test.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6555b74",
   "metadata": {},
   "source": [
    "## Implement desicion tree algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339be89",
   "metadata": {},
   "source": [
    "In this cell, you are going to implement your decision tree. Feel free to add more arguments to functions or add your desired functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b689aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(S):\n",
    "    return -(S.count(0)/len(S))*(math.log((S.count(0)/len(S)), 2) if S.count(0)!=0 else 0)-(S.count(1)/len(S))*(math.log((S.count(1)/len(S)), 2) if S.count(1)!=0 else 0)\n",
    "\n",
    "def gini(S):\n",
    "    return 1-((S.count(0)/len(S))**2+(S.count(1)/len(S))**2)\n",
    "\n",
    "def classify(x, y, attr):\n",
    "    out_x = []\n",
    "    out_y = []\n",
    "    col = []\n",
    "    for k in list(set(np.array(x).T.tolist()[attr])):\n",
    "        col.append(k)\n",
    "        out_x.append([])\n",
    "        out_y.append([])\n",
    "        for i, j in zip(x, y):\n",
    "            if (i[attr]==k):\n",
    "                out_x[-1].append(i)\n",
    "                out_y[-1].append(j)\n",
    "    return out_x, out_y, col\n",
    "\n",
    "def find_best_attr(x, y, metric):\n",
    "    if (len(set(y))==1):\n",
    "        label = y[0]\n",
    "        return 'leaf', label\n",
    "    label = (2*sum(y))//len(y)\n",
    "    if (metric=='entropy'):\n",
    "        IG = []\n",
    "        for i in range(len(x[0])):\n",
    "            v_x, v_y,_ = classify(x, y, i)\n",
    "            s = 0\n",
    "            for i, j in zip(v_x, v_y):\n",
    "                s+=len(i)/len(x)*H(j)\n",
    "            IG.append(H(y) - s)\n",
    "        attr = IG.index(max(IG))\n",
    "    if (metric=='gini'):\n",
    "        gini = []\n",
    "        for i in range(len(x[0])):\n",
    "            v_x, v_y,_ = classify(x, y, i)\n",
    "            s = 0\n",
    "            for i, j in zip(v_x, v_y):\n",
    "                s+=len(i)/len(x)*gini(j)\n",
    "            gini.append(s)\n",
    "        attr = gini.index(min(gini))\n",
    "    return attr, label\n",
    "\n",
    "\n",
    "class DecisionTree:\n",
    "     \n",
    "    def __init__(self, criterion='entropy', max_depth=math.inf):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        \n",
    "        criterion -- “gini” for the Gini impurity and “entropy” for the information gain. (default “entropy”)\n",
    "        max_depth -- The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure. (default=None)\n",
    "        \"\"\"\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "        self.tree = []\n",
    "        \n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Build a decision tree classifier from the training set (X, y).\n",
    "\n",
    "        Returns:\n",
    "        self : Fitted estimator\n",
    "        \"\"\"\n",
    "        q_x = [[x[:], None, None]]\n",
    "        q_y = [[y[:], None, None]]\n",
    "        attr, label = find_best_attr(x, y, 'entropy')\n",
    "        out_x, out_y, col = classify(x, y, attr)\n",
    "        self.root = attr\n",
    "        while len(q_x)!=0:\n",
    "            q = q_x.pop(0)[:]\n",
    "            d = q_y.pop(0)[:]\n",
    "            x = q[0]\n",
    "            y = d[0]\n",
    "            attr, label = find_best_attr(x, y, 'entropy')\n",
    "            self.tree.append([q[1], attr, q[2], label])\n",
    "            if(attr!='leaf'):\n",
    "                out_x, out_y, col = classify(x, y, attr)\n",
    "                for i, j, k in zip(out_x, out_y, col):\n",
    "                    q_x.append([i[:], attr, k])\n",
    "                    q_y.append([j[:], attr, k])\n",
    "        return\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Predict class value for X.\n",
    "\n",
    "        Returns:\n",
    "        y : The predicted classes\n",
    "        \"\"\"\n",
    "        k = self.root\n",
    "        c = 0\n",
    "        while k!='leaf':\n",
    "            c+=1\n",
    "            for i in self.tree:\n",
    "                if i[0]==k and x[k]==i[2]:\n",
    "                    k = i[1]\n",
    "                    label = i[3]\n",
    "                    break\n",
    "            if c>min(len(self.tree), self.max_depth):\n",
    "                break\n",
    "        return label\n",
    "        \n",
    "# a = [\n",
    "# ['s1','h2','h3','l4'],\n",
    "# ['s1','h2','h3','s4'],\n",
    "# ['o1','h2','h3','l4'],\n",
    "# ['r1','m2','h3','l4'],\n",
    "# ['r1','c2','n3','l4'],\n",
    "# ['r1','c2','n3','s4'],\n",
    "# ['o1','c2','n3','s4'],\n",
    "# ['s1','m2','h3','l4'],\n",
    "# ['s1','c2','n3','l4'],\n",
    "# ['r1','m2','n3','l4'],\n",
    "# ['s1','m2','n3','s4'],\n",
    "# ['o1','m2','h3','s4'],\n",
    "# ['o1','h2','n3','l4'],\n",
    "# ['r1','m2','h3','s4']\n",
    "# ]\n",
    "# b = [0,0,1,1,1,0,1,0,1,1,1,1,1,0]\n",
    "# d = DecisionTree('entropy',)\n",
    "# d.fit(a, b)\n",
    "# for i in a:\n",
    "#     print(d.predict(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c267b831",
   "metadata": {},
   "source": [
    "### Part 1 : Compare Gini and Entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "511ec5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_gini = DecisionTree('gini',)\n",
    "dt_entropy = DecisionTree('entropy',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb1f0ac",
   "metadata": {},
   "source": [
    "In this cell, fit both declared trees on the train set and predict values on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "826f7e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_entropy.fit(X_train, Y_train)\n",
    "dt_gini.fit(X_train, Y_train)\n",
    "Y_pred_entropy = []\n",
    "Y_pred_gini = []\n",
    "for i in X_test:\n",
    "    Y_pred_entropy.append(dt_entropy.predict(i))\n",
    "    Y_pred_gini.append(dt_gini.predict(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ecdffe",
   "metadata": {},
   "source": [
    "Plot confusion matrix for both decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a895cd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy: \n",
      "0.6557377049180327\n",
      "[[10 14]\n",
      " [ 7 30]]\n",
      "Gini: \n",
      "0.6557377049180327\n",
      "[[10 14]\n",
      " [ 7 30]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('Entropy: ')\n",
    "print(accuracy_score(Y_test, Y_pred_entropy))\n",
    "print(confusion_matrix(Y_test, Y_pred_entropy))\n",
    "print('Gini: ')\n",
    "print(accuracy_score(Y_test, Y_pred_gini))\n",
    "print(confusion_matrix(Y_test, Y_pred_gini))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e9f01f",
   "metadata": {},
   "source": [
    "### Part 2 : Let's add maximum depth!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819b7033",
   "metadata": {},
   "source": [
    "Define an array of different maximum depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6934e715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6721311475409836, 0.6721311475409836, 0.6557377049180327, 0.6557377049180327, 0.6557377049180327, 0.6557377049180327, 0.6557377049180327, 0.6557377049180327, 0.6557377049180327, 0.6557377049180327, 0.6557377049180327]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_depths = [2,3,4,5,6,7,8,9,10,11,12] # FILL THIS LIST WITH DESIRED VALUES\n",
    "accuracy_scores = []\n",
    "\n",
    "for max_depth in max_depths:\n",
    "    Y_pred_entropy = []\n",
    "    dt = DecisionTree(criterion='entropy', max_depth=max_depth) # Feel free to change the \"entropy\" to the \"gini\"\n",
    "    dt.fit(X_train, Y_train)\n",
    "\n",
    "    # FIT declared tree to the train set and predict values on the test set. then calcualte accuracy score on the test set\n",
    "    # Feel free to use the sklearn moudle for calcualting accuracy score.\n",
    "    for i in X_test:\n",
    "        Y_pred_entropy.append(dt.predict(i))\n",
    "\n",
    "    acc = accuracy_score(Y_test, Y_pred_entropy)\n",
    "    accuracy_scores.append(acc)\n",
    "\n",
    "print(accuracy_scores)\n",
    "plt.plot(max_depths, accuracy_scores)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8f43ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth : 2, Accuracy : 0.6721311475409836\n",
      "Depth : 3, Accuracy : 0.6721311475409836\n",
      "Depth : 4, Accuracy : 0.6557377049180327\n",
      "Depth : 5, Accuracy : 0.6557377049180327\n",
      "Depth : 6, Accuracy : 0.6557377049180327\n",
      "Depth : 7, Accuracy : 0.6557377049180327\n",
      "Depth : 8, Accuracy : 0.6557377049180327\n",
      "Depth : 9, Accuracy : 0.6557377049180327\n",
      "Depth : 10, Accuracy : 0.6557377049180327\n",
      "Depth : 11, Accuracy : 0.6557377049180327\n",
      "Depth : 12, Accuracy : 0.6557377049180327\n"
     ]
    }
   ],
   "source": [
    "for depth, score in zip(max_depths, accuracy_scores):\n",
    "    print(f\"Depth : {depth}, Accuracy : {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e81c1d",
   "metadata": {},
   "source": [
    "Now compare the accuracy score of decision trees with and without using the \"max_depth\" parameter and discuss the effects of limiting the maximum depth of decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc7f840",
   "metadata": {},
   "source": [
    "در دو حالت آنتروپی و جینی به درصد دقت یکسانی در اکثر آزمایشات رسیدم فقط در یک مورد دقت‌های متفاوت دادند که به نظرم به دلیل\n",
    "تعداد کم دیتا و ریز دسته بندی کردن برای داده‌های پیوسته که باعث یکسان شدن انتخاب ریشه‌ها توسط آنتروپی و جینی شده است می‌باشد\n",
    "هنگام کاهش عمق در اکثر آزمایشات دیده شد که هنگامی که عمق زیاد باشد درصد دقت کاهش پیدا می‌کند و بهترین درصد دقت در عمق های کم مثل ۲ یا ۳ دیده شد\n",
    "دلیل این اتفاق این است که هنگامی که عمق درخت زیاد شود درخت بر روی داده‌ آموزشی بیش‌برازش می‌کند بنابراین دقت آن بر روی داده‌ی تست کاهش پیدا می‌کند"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eab7c8994d7768231886659fa7e0d0b6bcd62a9e2119102ea3dd820e9b07d2f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
